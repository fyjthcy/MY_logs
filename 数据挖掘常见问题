1.训练集小的时候用什么分类算法？
答：高方差低偏差的分类器，朴素贝叶斯，比低偏差高方差的分类器，如k近邻或logistic回归更有优势，后者容易过拟合。训练集多，则相反。。。
2.数据和算法之间的关系？
答：数据集足够大，算法的区别并不大。对于特征的提取是更重要的一点，如果很在意准确率，可以尝试将不同分类器进行合并，构成新的模型。
3.常见机器学习方法的特点？
答：

朴素贝叶斯：
1).feature长度不同，要归一化为相同长度。
p(ci/w)=p(w/ci)p(ci)/p(w);
优点：小规模数据表现良好，适合多分类，适合增量式训练。
缺点：数据表达形式敏感。

决策树：
理解熵，信息增益的关系
优点：解释性强 比较适合确实属性的样本 能够处理不相关的特征
缺点：容易过拟合 随机森林比他要好


4.常见归一化方法？
答：
1)min-max标准化：x=(x-min)/(max-min);
2)X-score标准化：x=(x-u)/p; u为均值，p为标准差；
